%!TEX root = ms.tex
\section{Conclusion and future work}
\label{sec:conclusion}
In this paper, the use of information criteria to compare regression models under general linear restrictions for both fixed and random predictors is discussed. It is shown that general versions for KL-based discrepancy (AICc and RAICc, respectively) and squared error-based discrepancy (C$_p$ and RC$_p$, respectively) can be formulated as effectively unbiased estimators of predictive error (up to some terms that are free of the linear restrictions and hence are irrelevant when comparing criteria for different models). Model comparison based on the KL-based discrepancy measures are shown via simulations to be better-behaved than squared error-based discrepancies (including cross-validation) in selecting models with low predictive error.

The study of RAICc for variable selection in this paper focuses on OLS fits on pre-fixed predictors (e.g. nested predictors based on their physical orders in $X$). The discussion can be extended to other fitting procedures where the predictors in each subset are decided in a data-dependent way. For instance, \citet{tian2019use} discussed using AICc for best subset regression, and extending those results to the random-X scenario is a topic for future work. 

Note also that only restrictions on the regression coefficients are considered here, corresponding to restrictions on the regression portion of the model. It is also possible that the data analyst could be interested in restrictions on the distributional parameters of the predictors (restricting the variances of some predictors to be equal to each other, for example, or restricting covariances to follow a specified pattern such as autoregressive of order $1$ or compound symmetry), and it would be interesting to try to generalize the criteria discussed here to that situation.